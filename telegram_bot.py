import os
import requests
from dotenv import load_dotenv
from gradio_client import Client
from PIL import Image
import logging
from datetime import datetime

# === –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è ===
logging.basicConfig(
    filename='combined_app.log',
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - IMAGE_PROMPT: %(message)s'
)

# === –ó–∞–≥—Ä—É–∑–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è ===
load_dotenv()

class Config:
    OPENROUTER_API_KEY = os.getenv('OPENROUTER_API_KEY')
    TELEGRAM_BOT_TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')
    TELEGRAM_CHANNEL_ID = os.getenv('TELEGRAM_CHANNEL_ID')
    HF_TOKEN = os.getenv("HF_TOKEN")
    MODEL = os.getenv('MODEL', "qwen/qwen3-14b:free")
    IMAGE_MODEL = os.getenv('IMAGE_MODEL', "black-forest-labs/FLUX.1-schnell")

# === –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ===
INPUT_FILENAME = "input.txt"
OUTPUT_DIR = "images"
IMAGE_PROMPTS_FILE = "image_prompts.txt"
BACKUP_IMAGE_MODELS = [
    "black-forest-labs/FLUX.1-dev",
    "multimodalart/FLUX.1-merged",
    "runwayml/stable-diffusion-v1-5"
]

def setup():
    required_vars = ['OPENROUTER_API_KEY', 'TELEGRAM_BOT_TOKEN', 'TELEGRAM_CHANNEL_ID', 'HF_TOKEN']
    for var in required_vars:
        if not os.getenv(var):
            raise ValueError(f"‚ùå –ù–µ –∑–∞–¥–∞–Ω–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è {var} –≤ .env —Ñ–∞–π–ª–µ")

def format_for_telegram(text):
    if not text:
        return ""
    text = text.replace("```markdown", "").replace("```", "")
    text = text.replace("*", "").replace("_", "").replace("`", "")
    return text.strip()

def read_queries(file_path=INPUT_FILENAME):
    try:
        with open(file_path, "r", encoding="utf-8") as file:
            return [line.strip() for line in file if line.strip()]
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}")
        return []

def remove_first_prompt():
    try:
        with open(INPUT_FILENAME, "r", encoding="utf-8") as f:
            lines = f.readlines()
        
        if not lines:
            logging.info("–§–∞–π–ª –ø—Ä–æ–º–ø—Ç–æ–≤ –ø—É—Å—Ç")
            return True
        
        with open(INPUT_FILENAME, "w", encoding="utf-8") as f:
            f.writelines(lines[1:])
        
        logging.info(f"–£–¥–∞–ª–µ–Ω –ø–µ—Ä–≤—ã–π –ø—Ä–æ–º–ø—Ç. –û—Å—Ç–∞–ª–æ—Å—å {len(lines)-1} —Å—Ç—Ä–æ–∫.")
        return True
    
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")
        return False

def get_ai_response(query, max_retries=3):
    for attempt in range(1, max_retries + 1):
        try:
            headers = {
                "Authorization": f"Bearer {Config.OPENROUTER_API_KEY}",
                "Content-Type": "application/json"
            }

            data = {
                "model": Config.MODEL,
                "messages": [
                    {
                        "role": "system",
                        "content": (
                            "–¢—ã - –∫—Ä–µ–∞—Ç–∏–≤–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç-–º–µ–π–∫–µ—Ä –¥–ª—è Telegram –∫–∞–Ω–∞–ª–∞. "
                            "–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ—Å—Ç –¥–ª–∏–Ω–æ–π 500‚Äì700 —Å–∏–º–≤–æ–ª–æ–≤. "
                            "–î–æ–±–∞–≤—å —ç–º–æ–¥–∑–∏, —Ö—ç—à—Ç–µ–≥–∏ –∏ —Å–¥–µ–ª–∞–π –µ–≥–æ –ª–µ–≥–∫–æ —á–∏—Ç–∞–µ–º—ã–º. "
                            "–ù–µ –∏—Å–ø–æ–ª—å–∑—É–π Markdown."
                        )
                    },
                    {
                        "role": "user",
                        "content": query
                    }
                ],
                "max_tokens": 1000,
                "temperature": 0.75
            }

            response = requests.post(
                "https://openrouter.ai/api/v1/chat/completions",
                headers=headers,
                json=data,
                timeout=30
            )

            if response.status_code == 200:
                answer = response.json()['choices'][0]['message']['content'].strip()
                return format_for_telegram(answer)

            else:
                logging.warning(f"–û—à–∏–±–∫–∞ API –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ—Å—Ç–∞ (–ø–æ–ø—ã—Ç–∫–∞ {attempt}): {response.status_code}, {response.text}")

        except Exception as e:
            logging.warning(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ –ò–ò –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ—Å—Ç–∞ (–ø–æ–ø—ã—Ç–∫–∞ {attempt}): {e}")

    logging.error("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø–æ—Å—Ç –∑–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–æ–ø—ã—Ç–æ–∫")
    return f"üìå {query}\n\n–ö–æ–Ω—Ç–µ–Ω—Ç –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."

def save_prompt_to_file(prompt):
    """–§—É–Ω–∫—Ü–∏—è –¥–ª—è –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–æ–º—Ç–∞ –≤ —Ñ–∞–π–ª"""
    try:
        os.makedirs(os.path.dirname(IMAGE_PROMPTS_FILE) or '.', exist_ok=True)
        with open(IMAGE_PROMPTS_FILE, "a", encoding="utf-8") as f:
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            f.write(f"{timestamp} - {prompt}\n\n")
        return True
    except Exception as e:
        logging.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –ø—Ä–æ–º—Ç–∞: {e}")
        return False

def generate_image_prompt(post_text, max_retries=3):
    for attempt in range(1, max_retries + 1):
        try:
            headers = {
                "Authorization": f"Bearer {Config.OPENROUTER_API_KEY}",
                "Content-Type": "application/json"
            }

            user_content = (
                "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ —Å–ª–µ–¥—É—é—â–∏–π —Ç–µ–∫—Å—Ç –∏–∑ –ø–æ—Å—Ç–∞ –≤ Telegram –∏ —Å–æ—Å—Ç–∞–≤—å—Ç–µ –ø–æ–¥—Ä–æ–±–Ω—ã–π –∏ —ë–º–∫–∏–π –ø—Ä–æ–º—Ç –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ "
                "–¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä–æ–µ –∏–¥–µ–∞–ª—å–Ω–æ –ø–µ—Ä–µ–¥–∞—Å—Ç –µ–≥–æ —Å–º—ã—Å–ª –∏ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—É—é –∞—Ç–º–æ—Å—Ñ–µ—Ä—É. "
                "–£—á–∏—Ç—ã–≤–∞–π—Ç–µ —Å—Ç–∏–ª—å –ø–æ–¥–∞—á–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, –∫–ª—é—á–µ–≤—ã–µ —Ç–µ–º—ã, –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏ –≤–æ–∑–º–æ–∂–Ω—É—é —Ü–µ–ª–µ–≤—É—é –∞—É–¥–∏—Ç–æ—Ä–∏—é.\n\n"
                f"{post_text}\n\n"
                "–ù–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –Ω–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å, —Ç–µ–∫—Å—Ç–∞, –Ω–∞–¥–ø–∏—Å–µ–π, –±—É–∫–≤. –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Ä–µ–∞–ª–∏—Å—á–∏—á–Ω—ã–º –∏ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º, –ø—Ä–∏–≤–ª–µ–∫–∞—Ç—å –≤–Ω–∏–º–∞–Ω–∏–µ –∏ –ø–æ–¥—Ö–æ–¥–∏—Ç—å –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–µ—Ç—è—Ö."
            )

            data = {
                "model": Config.MODEL,
                "messages": [
                    {
                        "role": "system",
                        "content": (
                            "You are an expert prompt engineer for AI image generation. "
                            "Create detailed, vivid prompts in English that perfectly capture "
                            "the essence of the provided text. Focus on visual storytelling."
                        )
                    },
                    {
                        "role": "user",
                        "content": user_content
                    }
                ],
                "max_tokens": 1000,
                "temperature": 0.5
            }

            response = requests.post(
                "https://openrouter.ai/api/v1/chat/completions",
                headers=headers,
                json=data,
                timeout=30
            )

            if response.status_code == 200:
                result = response.json()
                if 'choices' in result and len(result['choices']) > 0:
                    prompt = result['choices'][0]['message']['content'].strip()
                    if prompt:
                        prompt = prompt.replace('"', '').replace("'", "")
                        logging.info(f"Generated image prompt: {prompt}")
                        save_prompt_to_file(prompt)
                        return prompt

            logging.warning(f"–û—à–∏–±–∫–∞ API –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ–º—Ç–∞ (–ø–æ–ø—ã—Ç–∫–∞ {attempt}): {response.status_code}, {response.text}")

        except Exception as e:
            logging.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ–º—Ç–∞ (–ø–æ–ø—ã—Ç–∫–∞ {attempt}): {e}")

    default_prompt = (
        "modern digital art, trending on artstation, ultra-detailed, "
        "vibrant colors, professional composition, social media style, "
        "eye-catching visual, 8k resolution"
    )
    logging.info(f"Using default prompt: {default_prompt}")
    save_prompt_to_file(default_prompt)
    return default_prompt

def get_working_image_model():
    model_list = [Config.IMAGE_MODEL] if Config.IMAGE_MODEL else []
    model_list.extend(BACKUP_IMAGE_MODELS)
    
    for model in model_list:
        try:
            client = Client(model, hf_token=Config.HF_TOKEN)
            return client, model
        except Exception as e:
            continue
    
    raise ValueError("–ù–∏ –æ–¥–Ω–∞ –∏–∑ –º–æ–¥–µ–ª–µ–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∞!")

def generate_image(client, prompt, model_name):
    try:
        if "FLUX.1-schnell" in model_name:
            result = client.predict(
                prompt=prompt,
                api_name="/infer"
            )
        else:
            result = client.predict(
                prompt=prompt,
                seed=0,
                width=1024,
                height=1024,
                guidance_scale=3.5,
                num_inference_steps=28,
                api_name="/infer"
            )
        
        return result[0]
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
        return None

def save_image(temp_path, prompt):
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    safe_prompt = "".join(
        c for c in prompt[:30] 
        if c.isalnum() or c in " _-"
    ).rstrip()
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_path = os.path.join(OUTPUT_DIR, f"{timestamp}_{safe_prompt}.png")
    
    try:
        with Image.open(temp_path) as img:
            img.save(output_path, "PNG", quality=95)
        return output_path
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
        return None

def send_post_with_image_to_telegram(text, image_path):
    try:
        url = f"https://api.telegram.org/bot{Config.TELEGRAM_BOT_TOKEN}/sendPhoto"
        with open(image_path, "rb") as photo:
            files = {"photo": photo}
            data = {"chat_id": Config.TELEGRAM_CHANNEL_ID, "caption": text[:1024]}
            response = requests.post(url, files=files, data=data, timeout=30)
            
            if response.status_code == 200:
                return True
            else:
                logging.error(f"–û—à–∏–±–∫–∞ Telegram API: {response.status_code}, {response.text}")
                return False
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ Telegram: {e}")
        return False

def main():
    try:
        setup()
    except ValueError as e:
        logging.error(f"–û—à–∏–±–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")
        return

    queries = read_queries()
    if not queries:
        logging.error("–í —Ñ–∞–π–ª–µ input.txt –Ω–µ—Ç –≤–æ–ø—Ä–æ—Å–æ–≤")
        return

    query = queries[0]

    # 1. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ—Å—Ç–∞
    post_text = get_ai_response(query)
    if not post_text:
        return

    # 2. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–º—Ç–∞ –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    image_prompt = generate_image_prompt(post_text)

    # 3. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    try:
        client, model_name = get_working_image_model()
        temp_image_path = generate_image(client, image_prompt, model_name)
        if not temp_image_path:
            return

        final_image_path = save_image(temp_image_path, image_prompt)
        if not final_image_path:
            return

        # 4. –û—Ç–ø—Ä–∞–≤–∫–∞ –≤ Telegram
        if send_post_with_image_to_telegram(post_text, final_image_path):
            remove_first_prompt()

    except Exception as e:
        logging.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")

if __name__ == "__main__":
    main()